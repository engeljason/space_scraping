{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from bs4 import BeautifulSoup\r\n",
    "from splinter import Browser\r\n",
    "import requests\r\n",
    "import os.path\r\n",
    "import pandas as pd\r\n",
    "import re\r\n",
    "\r\n",
    "def get_page(url):\r\n",
    "    executable_path = {\"executable_path\": \"C:/Users/Jason/bin/chromedriver\"}\r\n",
    "    browser = Browser(\"chrome\", **executable_path, headless=False)\r\n",
    "    browser.visit(url)\r\n",
    "    html = browser.html\r\n",
    "    browser.quit()\r\n",
    "    return html\r\n",
    "\r\n",
    "def get_soup(url, nickname):\r\n",
    "    html = get_page(url)\r\n",
    "    soup = BeautifulSoup(html, 'html.parser')\r\n",
    "    return soup\r\n",
    "\r\n",
    "# fast get soup to reduce Splinter calls\r\n",
    "def fget_soup(url, nickname):\r\n",
    "    if not os.path.isfile(nickname):\r\n",
    "        html = get_page(url)\r\n",
    "        with open(nickname, 'w') as file:\r\n",
    "            file.write(html)\r\n",
    "    with open(nickname, 'r') as html:\r\n",
    "        soup = BeautifulSoup(html, 'html.parser')\r\n",
    "    return soup\r\n",
    "\r\n",
    "\r\n",
    "#########################\r\n",
    "## RedPlanet news articles\r\n",
    "#########################\r\n",
    "\r\n",
    "def get_articles():\r\n",
    "    soup = get_soup(\"https://redplanetscience.com/\", \"redplanet.html\")\r\n",
    "\r\n",
    "    red_planet_titles = []\r\n",
    "    red_planet_text = []\r\n",
    "    for div in soup.find_all(\"div\"):\r\n",
    "        if 'content_title' in div['class']:\r\n",
    "            red_planet_titles.append(div.text)\r\n",
    "        if 'article_teaser_body' in div['class']:\r\n",
    "            red_planet_text.append(div.text)\r\n",
    "    return list(zip(red_planet_titles, red_planet_text))\r\n",
    "\r\n",
    "\r\n",
    "#########################\r\n",
    "## SpaceImages Mars image\r\n",
    "#########################\r\n",
    "\r\n",
    "def get_mars_image():\r\n",
    "    space_images_url = \"https://spaceimages-mars.com/\"\r\n",
    "    soup = get_soup(space_images_url, \"spaceimages.html\")\r\n",
    "\r\n",
    "    mars_image_url = space_images_url+ soup.find(\"img\", class_=\"headerimage\")['src']\r\n",
    "    return mars_image_url\r\n",
    "\r\n",
    "\r\n",
    "#########################\r\n",
    "## GalaxyFacts Mars Facts\r\n",
    "#########################\r\n",
    "\r\n",
    "def get_mars_fact_table():\r\n",
    "    soup = get_soup(\"https://galaxyfacts-mars.com/\", \"mars_facts.html\")\r\n",
    "\r\n",
    "    mars_table = soup.find('table', class_= 'table-striped')\r\n",
    "    mars_df = pd.read_html(str(mars_table))[0]\r\n",
    "    mars_table_html_from_pd = mars_df.to_html()\r\n",
    "    return mars_table_html_from_pd\r\n",
    "\r\n",
    "#########################\r\n",
    "## MarsHemispheres enhanced images\r\n",
    "#########################\r\n",
    "\r\n",
    "def get_mars_hemi_imgs():\r\n",
    "    galaxy_url = \"https://marshemispheres.com/\"\r\n",
    "    galaxy_facts = requests.get(galaxy_url)\r\n",
    "    soup = BeautifulSoup(galaxy_facts.text, \"html.parser\")\r\n",
    "\r\n",
    "    links = []\r\n",
    "    names = []\r\n",
    "    thumbs = []\r\n",
    "    for div in soup.find_all(\"div\", class_=\"description\"):\r\n",
    "        a = div.find('a')\r\n",
    "        links.append(a['href'])\r\n",
    "        names.append(a.find('h3').string)\r\n",
    "        thumbs.append(galaxy_url+div.parent.find(\"img\")[\"src\"])\r\n",
    "\r\n",
    "    # print(names)\r\n",
    "    # print(links)\r\n",
    "\r\n",
    "    img_links = []\r\n",
    "    for link in links:\r\n",
    "        link_page = requests.get(f'{galaxy_url}{link}')\r\n",
    "        link_soup = BeautifulSoup(link_page.text, 'html.parser')\r\n",
    "        dt = link_soup.find(string=\"Filename\").parent\r\n",
    "        image_link = dt.next_sibling.next_sibling.find('a')['href']\r\n",
    "        img_links.append(f'{galaxy_url}{image_link}')\r\n",
    "\r\n",
    "    # print(img_links)\r\n",
    "\r\n",
    "    mars_hemispheres = []\r\n",
    "    for name, link, thumb in zip(names, img_links, thumbs):\r\n",
    "        mars_hemispheres.append({'title': name, 'img_url' : link, 'thumb' : thumb})\r\n",
    "\r\n",
    "    # print(mars_hemispheres)\r\n",
    "    return mars_hemispheres\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}